{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZW-jvxSGz8nc"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, GridSearchCV\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, LogisticRegression #Ridge(L1) y Lasso(L2) agregan \"regularizacion\" : para cuando tengamos Underfitting o Overfitting\n",
        "from sklearn.metrics import accuracy_score, classification_report, ConfusionMatrixDisplay, confusion_matrix\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn import set_config\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "from sklearn.exceptions import FitFailedWarning, ConvergenceWarning\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
        "import xgboost as xgb\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from pathlib import Path\n",
        "from joblib import dump"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RS9bSCAn0AL1",
        "outputId": "85299164-11b1-4afb-9d71-4e34e954c15e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "preprocessor se guardo correctamente en artefacts/preprocessor/preprocessor.pkl\n",
            "preprocessor se guardo correctamente en artefacts/preprocessor/encoder.pkl\n",
            "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n",
            "model se guardo correctamente en artefacts/model/logreg.pkl\n",
            "\n",
            "\n",
            "--------------------------------\n",
            "\n",
            "Regresion Logistica\n",
            "\n",
            "Accuracy: 0.9725\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97       105\n",
            "           1       0.94      1.00      0.97        91\n",
            "           2       0.98      0.97      0.97        92\n",
            "           3       0.97      0.98      0.98       112\n",
            "\n",
            "    accuracy                           0.97       400\n",
            "   macro avg       0.97      0.97      0.97       400\n",
            "weighted avg       0.97      0.97      0.97       400\n",
            "\n",
            "Fitting 5 folds for each of 60 candidates, totalling 300 fits\n",
            "model se guardo correctamente en artefacts/model/svc.pkl\n",
            "\n",
            "\n",
            "--------------------------------\n",
            "\n",
            "SVM Lineal\n",
            "\n",
            "Accuracy: 0.8775\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98       105\n",
            "           1       0.76      0.74      0.75        91\n",
            "           2       0.75      0.77      0.76        92\n",
            "           3       0.97      0.99      0.98       112\n",
            "\n",
            "    accuracy                           0.88       400\n",
            "   macro avg       0.87      0.87      0.87       400\n",
            "weighted avg       0.88      0.88      0.88       400\n",
            "\n",
            "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n",
            "model se guardo correctamente en artefacts/model/svc.pkl\n",
            "\n",
            "\n",
            "--------------------------------\n",
            "\n",
            "SVM\n",
            "\n",
            "Accuracy: 0.975\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.94      0.97       105\n",
            "           1       0.93      1.00      0.96        91\n",
            "           2       0.99      0.97      0.98        92\n",
            "           3       0.98      0.99      0.99       112\n",
            "\n",
            "    accuracy                           0.97       400\n",
            "   macro avg       0.97      0.98      0.97       400\n",
            "weighted avg       0.98      0.97      0.98       400\n",
            "\n",
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "model se guardo correctamente en artefacts/model/dtc.pkl\n",
            "\n",
            "\n",
            "--------------------------------\n",
            "\n",
            "DTC\n",
            "\n",
            "Accuracy: 0.865\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.92      0.93       105\n",
            "           1       0.80      0.88      0.84        91\n",
            "           2       0.79      0.77      0.78        92\n",
            "           3       0.92      0.88      0.89       112\n",
            "\n",
            "    accuracy                           0.86       400\n",
            "   macro avg       0.86      0.86      0.86       400\n",
            "weighted avg       0.87      0.86      0.87       400\n",
            "\n",
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "model se guardo correctamente en artefacts/model/rfc.pkl\n",
            "\n",
            "\n",
            "--------------------------------\n",
            "\n",
            "Random Forest\n",
            "\n",
            "Accuracy: 0.905\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95       105\n",
            "           1       0.87      0.88      0.87        91\n",
            "           2       0.87      0.84      0.85        92\n",
            "           3       0.94      0.93      0.93       112\n",
            "\n",
            "    accuracy                           0.91       400\n",
            "   macro avg       0.90      0.90      0.90       400\n",
            "weighted avg       0.90      0.91      0.90       400\n",
            "\n",
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "model se guardo correctamente en artefacts/model/ab.pkl\n",
            "\n",
            "\n",
            "--------------------------------\n",
            "\n",
            "AdaBoost\n",
            "\n",
            "Accuracy: 0.745\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.86      0.87       105\n",
            "           1       0.67      0.70      0.69        91\n",
            "           2       0.62      0.52      0.56        92\n",
            "           3       0.77      0.86      0.81       112\n",
            "\n",
            "    accuracy                           0.74       400\n",
            "   macro avg       0.73      0.73      0.73       400\n",
            "weighted avg       0.74      0.74      0.74       400\n",
            "\n",
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "model se guardo correctamente en artefacts/model/gbc.pkl\n",
            "\n",
            "\n",
            "--------------------------------\n",
            "\n",
            "GradientBoost\n",
            "\n",
            "Accuracy: 0.91\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.95      0.95       105\n",
            "           1       0.89      0.92      0.91        91\n",
            "           2       0.85      0.87      0.86        92\n",
            "           3       0.93      0.89      0.91       112\n",
            "\n",
            "    accuracy                           0.91       400\n",
            "   macro avg       0.91      0.91      0.91       400\n",
            "weighted avg       0.91      0.91      0.91       400\n",
            "\n",
            "Fitting 5 folds for each of 18 candidates, totalling 90 fits\n",
            "model se guardo correctamente en artefacts/model/xgb.pkl\n",
            "\n",
            "\n",
            "--------------------------------\n",
            "\n",
            "XG Booost\n",
            "\n",
            "Accuracy: 0.9125\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.95      0.96       105\n",
            "           1       0.87      0.95      0.91        91\n",
            "           2       0.87      0.85      0.86        92\n",
            "           3       0.94      0.90      0.92       112\n",
            "\n",
            "    accuracy                           0.91       400\n",
            "   macro avg       0.91      0.91      0.91       400\n",
            "weighted avg       0.91      0.91      0.91       400\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# warnings para que no nos MUESTRE todo lo que hace el modelo\n",
        "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "\n",
        "class ML:\n",
        "  def __init__(self, X, y, verbose = True, plot = True, regression = None, classification = None, undersample= None, oversample = None, dump= None):\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.verbose = verbose\n",
        "    self.plot = plot\n",
        "    self.regression = regression\n",
        "    self.classification = classification\n",
        "    self.undersample = undersample\n",
        "    self.oversample = oversample\n",
        "    self.dump = dump\n",
        "\n",
        "\n",
        "\n",
        "  def dumpfolder(self, file, type = 'model', filename = None):\n",
        "    output_dir = Path('artefacts')/type\n",
        "    output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if filename is None:\n",
        "      filename = f'{type}.pkl'\n",
        "\n",
        "    try:\n",
        "      dump(file, output_dir/filename)\n",
        "      print(f'{type} se guardo correctamente en {output_dir/filename}')\n",
        "    except Exception as e:\n",
        "      print(f'error al guardar {type}: {e}')\n",
        "\n",
        "  def Preprocess (self):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(self.X, self.y, test_size=0.2, random_state=42)\n",
        "    num_cols = self.X.select_dtypes(exclude = 'object').columns\n",
        "    cat_cols = self.X.select_dtypes(include='object').columns\n",
        "\n",
        "    preprocessor = ColumnTransformer(\n",
        "        [\n",
        "            ('num', StandardScaler(), num_cols),\n",
        "            ('cat', OneHotEncoder(), cat_cols)\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    X_train = preprocessor.fit_transform(X_train)\n",
        "    X_test = preprocessor.transform(X_test)\n",
        "\n",
        "    if self.dump:\n",
        "      self.dumpfolder(preprocessor, type = 'preprocessor', filename = 'preprocessor.pkl')\n",
        "\n",
        "    if self.classification:\n",
        "\n",
        "      le = LabelEncoder()   #nombra a los tipos (de carros por ejemplo) con numeros para que le sea mas facil\n",
        "\n",
        "      y_train = le.fit_transform(y_train)\n",
        "      y_test = le.transform(y_test)\n",
        "\n",
        "      if self.dump:\n",
        "        self.dumpfolder(le, type = 'preprocessor', filename = 'encoder.pkl')\n",
        "\n",
        "    elif self.regression:\n",
        "      pass\n",
        "\n",
        "    if self.oversample:\n",
        "      smote = SMOTE(random_state=42, sampling_strategy = 'minority')\n",
        "      X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "    elif self.undersample:\n",
        "      rus = RandomUnderSampler(random_state=42)\n",
        "      X_train, y_train = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "    # Disminuir datos de las clases (del support) para que esten parejas todas, solo  en los datos del TRAIN, no en los del test (a ese no se le hace nada)\n",
        "    rus = RandomUnderSampler(random_state=42)\n",
        "    X_train, y_train = rus.fit_resample(X_train, y_train)\n",
        "\n",
        "    '''\n",
        "    # Generar datos para que esten parejas las clases, datos del TRAIN\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "    '''\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "  def LogReg(self, X_train, X_test, y_train, y_test):\n",
        "    lr = LogisticRegression()\n",
        "    lr_grid = [\n",
        "        {\n",
        "            'penalty': ['l1', 'l2', 'none'],\n",
        "            'C': [0.01, 0.1, 1, 10, 100],\n",
        "            'max_iter': [100, 1000, 2000],\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    grid_search = GridSearchCV(lr, lr_grid, cv=5, verbose = 1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    grid_best_params = grid_search.best_params_\n",
        "    lrfinal = LogisticRegression(**grid_best_params)\n",
        "    lrfinal.fit(X_train, y_train)\n",
        "\n",
        "    if self.dump:\n",
        "      self.dumpfolder(lrfinal, type = 'model', filename = 'logreg.pkl')\n",
        "\n",
        "    y_pred = lrfinal.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('\\n')\n",
        "      print('--------------------------------\\n')\n",
        "      print('Regresion Logistica\\n')\n",
        "      print(f'Accuracy: {accuracy}')\n",
        "      #Desgloce de como  clasifico cada clase con su accuracy\n",
        "      class_report = classification_report(y_test, y_pred)\n",
        "      print(class_report)\n",
        "\n",
        "    if self.plot:\n",
        "\n",
        "      #Matriz de confision, REALIZAR PARA SABER SI EL MODELO FUNCIONA BIEN\n",
        "      cm = confusion_matrix(y_test, y_pred)\n",
        "      disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "      disp.plot(cmap='Blues')\n",
        "      plt.show()               # Mostrar siempre para ver como el modelo esta clasificando los datos y saber que tan bueno es el modelo, no solo con el accuracy\n",
        "\n",
        "  def SVMLin(self, X_train, X_test, y_train, y_test):\n",
        "\n",
        "    svc = LinearSVC()\n",
        "\n",
        "    svc_grid = [\n",
        "        {\n",
        "            'C': [0.01, 0.1, 1, 10, 100],\n",
        "            'class_weight': [None, 'balanced'],\n",
        "            'fit_intercept': [True, False],\n",
        "            'penalty': ['l1', 'l2', 'none'],\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    grid_search = GridSearchCV(svc, svc_grid, cv=5, verbose = 1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    grid_best_params = grid_search.best_params_\n",
        "    svcfinal = LinearSVC(**grid_best_params)\n",
        "    svcfinal.fit(X_train, y_train)\n",
        "\n",
        "    if self.dump:\n",
        "      self.dumpfolder(svcfinal, type = 'model', filename = 'svc.pkl')\n",
        "\n",
        "    y_pred = svcfinal.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('\\n')\n",
        "      print('--------------------------------\\n')\n",
        "      print('SVM Lineal\\n')\n",
        "      print(f'Accuracy: {accuracy}')\n",
        "      class_report = classification_report(y_test, y_pred)\n",
        "      print(class_report)\n",
        "\n",
        "    if self.plot:\n",
        "      cm = confusion_matrix(y_test, y_pred)\n",
        "      disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "      disp.plot(cmap='Blues')\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def SVM(self, X_train, X_test, y_train, y_test):\n",
        "\n",
        "    svc = SVC()\n",
        "\n",
        "    svc_grid = [\n",
        "        {\n",
        "            'C': [0.01, 0.1, 1, 10, 100],\n",
        "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "            'gamma': ['scale', 'auto'],\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    grid_search = GridSearchCV(svc, svc_grid, cv=5, verbose = 1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    grid_best_params = grid_search.best_params_\n",
        "    svcfinal = SVC(**grid_best_params)\n",
        "    svcfinal.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "    if self.dump:\n",
        "      self.dumpfolder(svcfinal, type = 'model', filename = 'svm.pkl')\n",
        "\n",
        "    y_pred = svcfinal.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('\\n')\n",
        "      print('--------------------------------\\n')\n",
        "      print('SVM\\n')\n",
        "      print(f'Accuracy: {accuracy}')\n",
        "      class_report = classification_report(y_test, y_pred)\n",
        "      print(class_report)\n",
        "\n",
        "\n",
        "    if self.plot:\n",
        "      cm = confusion_matrix(y_test, y_pred)\n",
        "      disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "      disp.plot(cmap='Blues')\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "\n",
        "  def DecisionTree(self, X_train, X_test, y_train, y_test):\n",
        "\n",
        "    DTC = DecisionTreeClassifier()\n",
        "\n",
        "    DTC_grid = [\n",
        "        {\n",
        "            'criterion': ['gini', 'entropy'],\n",
        "            'splitter': ['best', 'random'],\n",
        "            'class_weight': [None, 'balanced'],\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    grid_search = GridSearchCV(DTC, DTC_grid, cv=5, verbose = 1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    grid_best_params = grid_search.best_params_\n",
        "    DTCfinal = DecisionTreeClassifier(**grid_best_params)\n",
        "    DTCfinal.fit(X_train, y_train)\n",
        "\n",
        "    if self.dump:\n",
        "      self.dumpfolder(DTCfinal, type = 'model', filename = 'dtc.pkl')\n",
        "\n",
        "    y_pred = DTCfinal.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('\\n')\n",
        "      print('--------------------------------\\n')\n",
        "      print('DTC\\n')\n",
        "      print(f'Accuracy: {accuracy}')\n",
        "      class_report = classification_report(y_test, y_pred)\n",
        "      print(class_report)\n",
        "\n",
        "    if self.plot:\n",
        "      cm = confusion_matrix(y_test, y_pred)\n",
        "      disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "      disp.plot(cmap='Blues')\n",
        "      plt.show()\n",
        "\n",
        "  '''\n",
        "    #Arbol de decision\n",
        "\n",
        "    from six import StringIO\n",
        "    from IPython.display import Image, display\n",
        "    from sklearn.tree import export_graphviz\n",
        "    import pydotplus\n",
        "\n",
        "    dot_data = StringIO()\n",
        "    export_graphviz(DTCfinal, out_file=dot_data, filled=True, rounded=True, special_characters=True)\n",
        "\n",
        "    graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
        "    display(Image(graph.create_png()))  # Aquí sí se muestra en la celda\n",
        "    graph.write_png('arbol.png')\n",
        "  '''\n",
        "\n",
        "  def RandomForest(self, X_train,X_test, y_train, y_test):\n",
        "\n",
        "    RFC = RandomForestClassifier()\n",
        "\n",
        "    RF_grid = [\n",
        "        {\n",
        "            'criterion': ['gini', 'entropy'],\n",
        "            'class_weight': ['balanced', 'balanced_subsample', None],\n",
        "            'warm_start': [True, False]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    grid_search = GridSearchCV(RFC, RF_grid, cv=5, verbose = 1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    grid_best_params = grid_search.best_params_\n",
        "    RFCfinal = RandomForestClassifier(**grid_best_params)\n",
        "    RFCfinal.fit(X_train, y_train)\n",
        "\n",
        "    if self.dump:\n",
        "      self.dumpfolder(RFCfinal, type = 'model', filename = 'rfc.pkl')\n",
        "\n",
        "    y_pred = RFCfinal.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('\\n')\n",
        "      print('--------------------------------\\n')\n",
        "      print('Random Forest\\n')\n",
        "      print(f'Accuracy: {accuracy}')\n",
        "      class_report = classification_report(y_test, y_pred)\n",
        "      print(class_report)\n",
        "\n",
        "    if self.plot:\n",
        "      cm = confusion_matrix(y_test, y_pred)\n",
        "      disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "      disp.plot(cmap='Blues')\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "  def AdaBoost(self, X_train,X_test, y_train, y_test):\n",
        "\n",
        "    AB = AdaBoostClassifier()\n",
        "\n",
        "    AB_grid = [\n",
        "        {\n",
        "            'n_estimators': [10, 50, 100],\n",
        "            'learning_rate': [0.1, 0.5, 1],\n",
        "            'algorithm': ['SAMME', 'SAMME.R']\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    grid_search = GridSearchCV(AB, AB_grid, cv=5, verbose = 1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    grid_best_params = grid_search.best_params_\n",
        "    ABfinal = AdaBoostClassifier(**grid_best_params)\n",
        "    ABfinal.fit(X_train, y_train)\n",
        "\n",
        "    if self.dump:\n",
        "      self.dumpfolder(ABfinal, type = 'model', filename = 'ab.pkl')\n",
        "\n",
        "    y_pred = ABfinal.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('\\n')\n",
        "      print('--------------------------------\\n')\n",
        "      print('AdaBoost\\n')\n",
        "      print(f'Accuracy: {accuracy}')\n",
        "      class_report = classification_report(y_test, y_pred)\n",
        "      print(class_report)\n",
        "\n",
        "    if self.plot:\n",
        "      cm = confusion_matrix(y_test, y_pred)\n",
        "      disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "      disp.plot(cmap='Blues')\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "  def GradientBoost(self, X_train,X_test, y_train, y_test):\n",
        "\n",
        "    GBC = GradientBoostingClassifier()\n",
        "\n",
        "    GBC_grid = [\n",
        "        {\n",
        "            'n_estimators': [10, 50, 100],\n",
        "            'learning_rate': [0.1, 0.5, 1],\n",
        "            'subsample': [0.8, 1.0],\n",
        "            #'max_depth': [3, 5, 7]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    grid_search = GridSearchCV(GBC, GBC_grid, cv=5, verbose = 1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    grid_best_params = grid_search.best_params_\n",
        "    GBCfinal = GradientBoostingClassifier(**grid_best_params)\n",
        "    GBCfinal.fit(X_train, y_train)\n",
        "\n",
        "    if self.dump:\n",
        "      self.dumpfolder(GBCfinal, type = 'model', filename = 'gbc.pkl')\n",
        "\n",
        "    y_pred = GBCfinal.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('\\n')\n",
        "      print('--------------------------------\\n')\n",
        "      print('GradientBoost\\n')\n",
        "      print(f'Accuracy: {accuracy}')\n",
        "      class_report = classification_report(y_test, y_pred)\n",
        "      print(class_report)\n",
        "\n",
        "    if self.plot:\n",
        "      cm = confusion_matrix(y_test, y_pred)\n",
        "      disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "      disp.plot(cmap='Blues')\n",
        "      plt.show()\n",
        "\n",
        "\n",
        "  def XGBoost(self, X_train,X_test, y_train, y_test):\n",
        "\n",
        "    XGB = xgb.XGBClassifier()\n",
        "\n",
        "    XGB_grid = [\n",
        "        {\n",
        "            'n_estimators': [10, 50, 100],\n",
        "            'learning_rate': [0.1, 0.5, 1],\n",
        "            'subsample': [0.8, 1.0],\n",
        "            #'max_depth': [3, 5, 7]\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    grid_search = GridSearchCV(XGB, XGB_grid, cv=5, verbose = 1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    grid_best_params = grid_search.best_params_\n",
        "    XGBfinal = xgb.XGBClassifier(**grid_best_params)\n",
        "    XGBfinal.fit(X_train, y_train)\n",
        "\n",
        "    if self.dump:\n",
        "      self.dumpfolder(XGBfinal, type = 'model', filename = 'xgb.pkl')\n",
        "\n",
        "    y_pred = XGBfinal.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    if self.verbose:\n",
        "      print('\\n')\n",
        "      print('--------------------------------\\n')\n",
        "      print('XG Booost\\n')\n",
        "      print(f'Accuracy: {accuracy}')\n",
        "      class_report = classification_report(y_test, y_pred)\n",
        "      print(class_report)\n",
        "\n",
        "    if self.plot:\n",
        "      cm = confusion_matrix(y_test, y_pred)\n",
        "      disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "      disp.plot(cmap='Blues')\n",
        "      plt.show()\n",
        "\n",
        "  def Run(self):\n",
        "    X_train, X_test, y_train, y_test = self.Preprocess()\n",
        "    #self.LogReg(X_train, X_test, y_train, y_test)\n",
        "    #self.SVMLin(X_train, X_test, y_train, y_test)\n",
        "    self.SVM(X_train, X_test, y_train, y_test)\n",
        "    #self.DecisionTree(X_train, X_test, y_train, y_test)\n",
        "    #self.RandomForest(X_train, X_test, y_train, y_test)\n",
        "    #self.AdaBoost(X_train, X_test, y_train, y_test)\n",
        "    #self.GradientBoost(X_train, X_test, y_train, y_test)\n",
        "    #self.XGBoost(X_train, X_test, y_train, y_test)\n",
        "\n",
        "\n",
        "'''\n",
        "df = pd.read_csv('/content/drive/MyDrive/used_car_price_dataset_extended.csv')\n",
        "#print(df.head())\n",
        "\n",
        "X = df.drop(['transmission'], axis=1)\n",
        "y = df['transmission']\n",
        "\n",
        "X_train, X_test, y_train, y_test = Preprocess(X,y)\n",
        "\n",
        "LogReg(X_train, X_test, y_train, y_test)\n",
        "'''\n",
        "\n",
        "test_pd = pd.read_csv('/workspaces/MLpruebaWebApp/test.csv')\n",
        "train_pd = pd.read_csv('/workspaces/MLpruebaWebApp/train.csv')\n",
        "df2 = pd.concat([test_pd, train_pd])\n",
        "#print(df2.head())\n",
        "\n",
        "df2.drop(['id'], axis = 1, inplace = True)\n",
        "df2.dropna(inplace = True)\n",
        "\n",
        "X = df2.drop(['price_range'], axis=1)\n",
        "y = df2['price_range']\n",
        "\n",
        "MLTrain = ML(X, y, classification = True, dump = True, plot = False, verbose = True)\n",
        "MLTrain.Run()\n",
        "\n",
        "\n",
        "\n",
        "#Saber cuales son los parametros disponibles\n",
        "#svc = LinearSVC()\n",
        "#print(svc.get_params())\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
